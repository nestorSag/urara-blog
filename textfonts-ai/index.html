<!doctype html>
<html lang="en-US">
  <head prefix="og: https://ogp.me/ns#">
    <meta charset="utf-8" />
    <meta name="generator" content="gh:importantimport/urara" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="manifest" crossorigin="use-credentials" href="/manifest.webmanifest" />
    <link rel="alternate" type="application/feed+json" href="/feed.json" />
    <link rel="alternate" type="application/atom+xml" href="/atom.xml" />
    <link rel="sitemap" type="application/xml" href="/sitemap.xml" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
    <meta http-equiv="content-security-policy" content="style-src 'self' 'unsafe-inline' https://giscus.app">
		<link href="../_app/immutable/assets/0.38746bfc.css" rel="stylesheet">
		<link rel="modulepreload" href="../_app/immutable/entry/start.18c6e970.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/scheduler.9b9e513e.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/singletons.2588bb0b.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/index.834d9e00.js">
		<link rel="modulepreload" href="../_app/immutable/entry/app.fc048ece.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/preload-helper.a4192956.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/index.781c9930.js">
		<link rel="modulepreload" href="../_app/immutable/nodes/0.fd7f0827.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/posts.80c9a437.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/icon.4e974116.js">
		<link rel="modulepreload" href="../_app/immutable/nodes/5.6a7b6552.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/post_layout.65b0bc7d.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/footer.ec2e7159.js"><title>Training Generative Models for Typefaces | Home</title><!-- HEAD_svelte-1592q3p_START --><!-- HEAD_svelte-1592q3p_END --><!-- HEAD_svelte-1kxdj3d_START --><link rel="shortcut icon" href="/favicon.png" sizes="48x48" type="image/png"><link rel="apple-touch-icon" href="/assets/any@180.png" sizes="180x180" type="image/png"><link rel="icon" href="/assets/any@192.png" sizes="192x192" type="image/png"><!-- HEAD_svelte-1kxdj3d_END --><!-- HEAD_svelte-1g590ms_START --><meta name="theme-color"><!-- HEAD_svelte-1g590ms_END --><!-- HEAD_svelte-abrfj_START --><meta name="author" content="Nestor Sanchez"><link rel="canonical" href="https://urara-demo.netlify.app/textfonts-ai">  <meta name="keywords" content="computer vision, generative models"> <!-- HEAD_svelte-abrfj_END --><!-- HEAD_svelte-4dky5b_START --><meta property="og:site_name" content="Home"><meta property="og:locale" content="en-US"><meta property="og:type" content="article"> <meta property="og:title" content="Training Generative Models for Typefaces">  <meta property="og:image" content="https://urara-demo.netlify.app/textfonts-ai/images/tensor-fonts.gif"> <meta name="twitter:card" content="summary_large_image"> <meta property="article:tag" content="computer vision"><meta property="article:tag" content="generative models"> <meta property="og:url" content="https://urara-demo.netlify.app/textfonts-ai"> <meta property="article:author" content="Nestor Sanchez"> <meta property="article:published_time" content="2021-07-31T00:00:00.000Z"> <meta property="article:modified_time" content="2024-01-21T20:10:06.855Z"><!-- HEAD_svelte-4dky5b_END -->
  </head>
  <body itemscope itemtype="https://schema.org/WebPage">
    <div style="display: contents">      <header id="header" class="fixed z-50 w-full transition-all duration-500 ease-in-out border-b-2 border-transparent max-h-[4.125rem] false"><div class="navbar"><div class="navbar-start">  <div class="dropdown lg:hidden"><label for="navbar-dropdown" tabindex="0" class="btn btn-square btn-ghost" data-svelte-h="svelte-rz1qrs"><span class="i-heroicons-outline-menu-alt-1"></span></label> <ul id="navbar-dropdown" tabindex="0" class="menu menu-compact dropdown-content bg-base-100 text-base-content shadow-lg rounded-box min-w-max max-w-52 p-2"><li><a href="/about">About</a> </li></ul></div> <div class="swap order-last hidden lg:inline-grid"><button class="swap-on btn btn-ghost text-base font-normal normal-case transition-all duration-200 hidden"></button> <ul class="swap-off menu menu-horizontal p-0"><li><a class="!rounded-btn" href="/about">About</a> </li></ul></div> <a href="/" class="btn btn-ghost normal-case text-lg">Home</a></div> <div class="navbar-end"> <div id="change-theme" class="dropdown dropdown-end">  <div tabindex="0" class="btn btn-square btn-ghost" data-svelte-h="svelte-1qtp8cz"><span class="i-heroicons-outline-color-swatch"></span></div>   <ul tabindex="0" class="flex flex-nowrap shadow-2xl menu dropdown-content bg-base-100 text-base-content rounded-box w-52 p-2 gap-2 overflow-y-auto max-h-[21.5rem]"><button data-theme="cmyk" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">üñ® Light</p> <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div> </button><button data-theme="dracula" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">üßõ Dark</p> <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div> </button><button data-theme="valentine" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">üå∏ Valentine</p> <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div> </button><button data-theme="aqua" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">üí¶ Aqua</p> <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div> </button><button data-theme="synthwave" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">üåÉ Synthwave</p> <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div> </button><button data-theme="night" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">üåÉ Night</p> <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div> </button><button data-theme="lofi" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">üé∂ Lo-Fi</p> <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div> </button><button data-theme="lemonade" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">üçã Lemonade</p> <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div> </button><button data-theme="cupcake" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">üßÅ Cupcake</p> <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div> </button><button data-theme="garden" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">üè° Garden</p> <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div> </button><button data-theme="retro" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">üåá Retro</p> <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div> </button><button data-theme="black" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">üñ§ Black</p> <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div> </button></ul></div></div></div></header> <button id="totop" aria-label="scroll to top" class="fixed grid group btn btn-circle btn-lg border-none backdrop-blur bottom-6 right-6 z-50 duration-500 ease-in-out btn-ghost bg-base-100/30 md:bg-base-200/30 translate-y-24"><div class="radial-progress text-accent transition-all duration-500 ease-in-out group-hover:text-accent-focus col-start-1 row-start-1" style="--size:4rem; --thickness: 0.25rem; --value:undefined;"></div> <div class="border-4 border-base-content/10 group-hover:border-transparent col-start-1 row-start-1 rounded-full w-full h-full p-4 grid duration-500 ease-in-out" data-svelte-h="svelte-hwvjh5"><span class="i-heroicons-solid-chevron-up !w-6 !h-6"></span></div></button> <div class="bg-base-100 md:bg-base-200 min-h-screen pt-16 md:pb-8 lg:pb-16">  <div class="flex flex-col flex-nowrap justify-center xl:flex-row xl:flex-wrap"><div class="flex-1 w-full order-first ease-out transform mx-auto xl:mr-0 xl:ml-0"></div> <div class="flex-1 w-full xl:order-last ease-out transform mx-auto xl:ml-0 xl:mr-0"></div> <div class="flex-none w-full max-w-screen-md mx-auto xl:mx-0"><article itemscope itemtype="https://schema.org/BlogPosting" itemprop="blogPost" class="h-entry card bg-base-100 rounded-none md:rounded-box md:shadow-xl overflow-hidden z-10 md:mb-8 lg:mb-16">   <div class="card-body gap-0 "><div class="flex flex-col gap-2"><figure class="md:order-last rounded-box shadow-xl mb-4 flex-col gap-2 -mx-4 -mt-8 md:mt-0"><img src="/textfonts-ai/images/tensor-fonts.gif" alt="/textfonts-ai/images/tensor-fonts.gif" class="u-featured" loading="lazy" decoding="async"></figure> <div class="flex font-semibold gap-1.5"><a rel="author" class="opacity-75 hover:opacity-100 hover:text-primary duration-500 ease-in-out p-author h-card" href="https://urara-demo.netlify.app">Nestor Sanchez</a> <span class="opacity-50" data-svelte-h="svelte-1edzios">/</span> <a href="/textfonts-ai" class="u-url u-uid swap group/time"><time class="group-hover/time:opacity-0 font-semibold opacity-75 duration-500 ease-in-out mr-auto dt-published" datetime="2021-07-31T00:00:00.000Z" itemprop="datePublished">Saturday 31 Jul 21</time> <time class="opacity-0 group-hover/time:opacity-100 font-semibold text-primary duration-500 ease-in-out mr-auto dt-updated" datetime="2024-01-21T20:10:06.855Z" itemprop="dateModified">Sunday 21 Jan 24</time></a></div> <h1 itemprop="name headline" class="card-title text-3xl mb-8 p-name">Training Generative Models for Typefaces</h1> </div> <main itemprop="articleBody" class="urara-prose prose e-content"><p data-svelte-h="svelte-nendkn"><em>You can find <a href="https://github.com/nestorSag/textfont-ai" rel="nofollow noopener noreferrer external" target="_blank">this project‚Äôs repository on Github</a>, along with pretrained models and an interactive Dash web app.</em></p> <h2 id="motivation" data-svelte-h="svelte-1qh4qj0"><a href="#motivation">Motivation</a></h2> <p data-svelte-h="svelte-1vjrv74">At some point last year I was watching one of the episodes of <a href="https://en.wikipedia.org/wiki/Abstract%3A_The_Art_of_Design" rel="nofollow noopener noreferrer external" target="_blank">Abstract: the art of design</a> on Netflix, when I realised typeface generation was possibly a low hanging fruit from a machine learning perspective. Deep generative models have been shown to achieve impressive results in a variety of tasks, particularly image generation, and this includes datasets such as faces, landscapes and even painting styles, so it is reasonable to expect they wouldn‚Äôt also excel at typeface generation.</p> <p data-svelte-h="svelte-1yz8p5w">This is not a new idea, for example in <a href="https://distill.pub/2017/aia/" rel="nofollow noopener noreferrer external" target="_blank">this article</a> they do exactly that, and approach the problem from the broader context of AI-assisted design. There are also a few Github repositories on the subject. I thought it would be fun to give it a shot myself. However, I did not try to produce typeface files per se but only typeface images, i.e. images of typeface characters, as the former would involve an awful lot of work dealing with the internal complexities of <code>otf</code> and related file formats.</p> <h2 id="data" data-svelte-h="svelte-14ht7vg"><a href="#data">Data</a></h2> <p data-svelte-h="svelte-wp8n64">The main problem here was to get data. Google makes their fonts publicly available, so thats around 4k examples. There are plenty of websites that offer free fonts online, but they don‚Äôt have an API of course, so there was no other way than scraping a few of them. In the end I got a bit under 130k fonts, or around 20 GB of images.</p> <p data-svelte-h="svelte-1yxkc6i">Mapping fonts to labeled images ready for model consumption was relatively easy, with an Apache Beam job on Google Cloud extracting 64-by-64 character images, and Tensorflow‚Äôs <code>Dataset</code> abstraction to consume remote files. Being free fonts, there were lots of corrupted files, corrupted characters within otherwise ok files, mislabeled characters, and fonts that looked nothing like characters.</p> <p data-svelte-h="svelte-1i8z3r2">I did train a classifier on the dataset and discarded all misclassified characters (around 10%); discarded images were mostly fonts or characters that were just too extravagant or simply defective, and I found that this improved the quality of generative models downstream. I also restricted the character set to uppercase to save a bit of time.</p> <h2 id="architecture" data-svelte-h="svelte-m3c4bv"><a href="#architecture">Architecture</a></h2> <p data-svelte-h="svelte-82gawe">Once plenty of clean data was available the next problem was deciding on a model architecture. I am not an expert in generative models, but thought the architecture outlined in <a href="https://arxiv.org/abs/1511.05644" rel="nofollow noopener noreferrer external" target="_blank">Adversarial Autoencoders by Goodfellow et all</a> looked good for this problem, as it enabled the model to also receive label information. I ended up doing one slight modification to this starting architecture, and the workflow looked like the following diagram (<strong>this might be hard to see with a dark background</strong>):</p> <p><picture><source srcset="/_app/immutable/assets/architecture.4a83bda6.avif 736w" type="image/avif"> <img src="/textfonts-ai/images/architecture.png" alt="architecture" class="rounded-lg my-2" loading="lazy" decoding="async"></picture></p> <p data-svelte-h="svelte-1j8344u">The only difference with the paper I mentioned is that I split the encoding phase in 2: first the image is encoded by an <em>image encoder</em>, then a <em>full encoder</em> takes the encoded image features <em>and</em> the labels (this is, the one-hot-encoded charater labels) to finally produce the embedded style representation. I did this hoping that the labels help not only on the decoding phase but also on the encoding one, say, by underlining the right features given the character label, e.g. if it‚Äôs an H, curviness is probably more important to the font‚Äôs style than if its a C, which I hoped would speed up training.</p> <h3 id="character-style-models" data-svelte-h="svelte-1mmysz2"><a href="#character-style-models">Character style models</a></h3> <p data-svelte-h="svelte-1sw7vkl">The following image shows one of the model‚Äôs style components for a randomly sampled font, once the model plateaud to a MSE of around 0.020 (this is the pixelwise MSE using normalised pixels in [0,1]) by training it with minibatches of randomly sampled character images across the dataset:</p> <p><img src="/textfonts-ai/images/chars.gif" alt="chars" class="rounded-lg my-2" loading="lazy" decoding="async"> <em data-svelte-h="svelte-qis0vt">Transition through a straight line in feature space between two randomly generated fonts.</em></p> <p data-svelte-h="svelte-178cxlz">There was a caveat though: generating all characters for a given style vector does not necessarily produce consistent image styles across the character set. I think this is because the model is only encoding the style of individual characters, as during training there is nothing that indicates any association between characters from the same font, and so, the latent style space ends up encoding styles slightly differently for different characters. To be fair, this was a relatively uncommon occurrence, but it did mean that this model wasn‚Äôt ideal for font generation.</p> <h3 id="font-style-models-a-self-supervised-approach" data-svelte-h="svelte-1b7m0xe"><a href="#font-style-models-a-self-supervised-approach">Font style models: a self-supervised approach</a></h3> <p data-svelte-h="svelte-18m7k43">In order to address the caveat mentioned above, I started taking font minibatches rather than image minibatches; this restricted the training to around 70k examples of fonts that were complete (i.e., no character was lost due to corrupted data or misclassification). The trick here was to use a bit of self supervised learning to try and make the model learn the fonts‚Äô style rather than the character style.</p> <p data-svelte-h="svelte-v0ns15">To do this, I shuffled the images and labels randomly when passing them to the decoder. So for example, the decoder might get the style vector from an ‚ÄòA‚Äô, but be required to reconstruct a ‚ÄòB‚Äô instead, which should be possible to do from just the style vector and the one-hot-encoded label for ‚ÄòB‚Äô. This worked, and the styles were now consistent across characters for all style vectors, but the images were more blurry than I expected, even after the model plateaued, with a mean squared error of 0.075:</p> <p><img src="/textfonts-ai/images/fonts.gif" alt="fonts" class="rounded-lg my-2" loading="lazy" decoding="async"> <em data-svelte-h="svelte-qis0vt">Transition through a straight line in feature space between two randomly generated fonts.</em></p> <p data-svelte-h="svelte-1nbpcj9">An interesting phenomenon was that this model consistently used just 5 dimensions in the style space even when there were more than that, making the rest useless; I suspect this means that there are (broadly speaking) only as many high-level characteristics that can be generalised from a single character to entire font styles, e.g. tickness, height/width ratio and so on.</p> <h3 id="font-style-models-fonts-as-26-channel-images" data-svelte-h="svelte-mhfqlc"><a href="#font-style-models-fonts-as-26-channel-images">Font style models: fonts as 26-channel images</a></h3> <p data-svelte-h="svelte-28uau8">My second attempt was to take fonts as images with 26 channels where each channel was associated to a character. With this architecture, there was no need for labels anymore, as now channels acted implicitly as labels; since labels were gone, there wasn‚Äôt any need for splitting the encoding stage in 2 parts, so the whole setup reduced to the usual autoencoder architecture, plus the discriminator network on the side, simplifying things quite a bit.</p> <p data-svelte-h="svelte-tsszeu">This model worked better in general, achieving a lower reconstruction error and having faster training times. Since fonts are passed as multi-channel images, this is less intensive on the GPU‚Äôs memory as well, because intermediate representations are per-font and not per-image.</p> <p><img src="/textfonts-ai/images/tensor-fonts.gif" alt="fonts" class="rounded-lg my-2" loading="lazy" decoding="async"> <em data-svelte-h="svelte-qis0vt">Transition through a straight line in feature space between two randomly generated fonts.</em></p> <p data-svelte-h="svelte-1mte2cv">I have to admit all results looked worse than expected at first. Then again, training high-quality generative models is not easy. Anyway, I think with a bit more data to generalise better, and with a sequence model to map images to points on the plane, (and with an expert that helps me navigate the technical aspects of font files!) it would even be possible to generate usable font files and not just images. Maybe this would be a nice bit of help for designers, to have a starting point when they set out to create a new font.</p> <p data-svelte-h="svelte-1m84kyc">This project is available on <a href="https://github.com/nestorSag/textfont-ai" rel="nofollow noopener noreferrer external" target="_blank">Github</a>, along with some pretrained decoders, and a Dash app in which to visualise style spaces.</p> <h2 id="lessons-in-mlops" data-svelte-h="svelte-r9vgwr"><a href="#lessons-in-mlops">Lessons in MLOps</a></h2> <p data-svelte-h="svelte-rhpt24">This project was more than anything an excuse to get my hands dirty with MLOps practices, and I placed a lot of emphasis on this along the project. A few lessons I learned:</p> <ul data-svelte-h="svelte-1s7x2od"><li><p>Experiment tracking does make a difference in project organisation, and MLFlow is a great tool for this</p></li> <li><p>Configuration became the project‚Äôs center of gravity. Comprehensive YAML configuration schemas is what enabled adding complexity without chaos as a byproduct.</p></li></ul></main> <div class="divider mt-4 mb-0"></div> <div><a href="/?tags=computer vision" class="btn btn-sm btn-ghost normal-case mt-2 mr-2 p-category">#computer vision </a><a href="/?tags=generative models" class="btn btn-sm btn-ghost normal-case mt-2 mr-2 p-category">#generative models </a></div></div>  </article> <footer id="footer" class="footer footer-center bg-base-300 text-base-content shadow-inner p-8 md:rounded-box sticky bottom-0 z-0 md:static "><div class="prose"><p><a href="/atom.xml" rel="noopener noreferrer external" target="_blank">Feed</a> <span class="mr-1" data-svelte-h="svelte-1qx196n">¬∑</span><a href="/sitemap.xml" rel="noopener noreferrer external" target="_blank">Sitemap</a>  <br>
      Copyright ¬© 2024 Nestor Sanchez <br>
      Powered by
      <a rel="noopener noreferrer external" target="_blank" class="tooltip tooltip-secondary hover:text-secondary" data-tip="üå∏ [Œ¥] - Based on MDsveX & SvelteKit üå∏" href="https://github.com/importantimport/urara" data-svelte-h="svelte-urea7w">Urara</a> </p></div></footer></div></div></div> 
			<script type="application/json" data-sveltekit-fetched data-url="/posts.json">{"status":200,"statusText":"","headers":{},"body":"[{\"title\":\"A Generative Model For English Town Names\",\"tags\":[\"NLP\",\"generative models\"],\"image_caption\":\"Styles across one of the dimensions in latent space\",\"image\":\"/town-name-generator/images/sign.jpg\",\"created\":\"2024-01-18T00:00:00.000Z\",\"updated\":\"2024-01-21T20:10:06.891Z\",\"images\":[],\"slug\":\"/town-name-generator/+page.md\",\"path\":\"/town-name-generator\",\"toc\":[{\"depth\":2,\"title\":\"Motivation\",\"slug\":\"motivation\"},{\"depth\":2,\"title\":\"Data\",\"slug\":\"data\"},{\"depth\":2,\"title\":\"Architecture\",\"slug\":\"architecture\"},{\"depth\":2,\"title\":\"Results\",\"slug\":\"results\"},{\"depth\":1,\"title\":\"Code\",\"slug\":\"code\"}],\"type\":\"article\",\"html\":\"\"},{\"title\":\"Training Generative Models for Typefaces\",\"tags\":[\"computer vision\",\"generative models\"],\"image_caption\":\"Styles across one of the dimensions in latent space\",\"image\":\"/textfonts-ai/images/tensor-fonts.gif\",\"created\":\"2021-07-31T00:00:00.000Z\",\"updated\":\"2024-01-21T20:10:06.855Z\",\"images\":[],\"slug\":\"/textfonts-ai/+page.md\",\"path\":\"/textfonts-ai\",\"toc\":[{\"depth\":2,\"title\":\"Motivation\",\"slug\":\"motivation\"},{\"depth\":2,\"title\":\"Data\",\"slug\":\"data\"},{\"depth\":2,\"title\":\"Architecture\",\"slug\":\"architecture\"},{\"depth\":3,\"title\":\"Character style models\",\"slug\":\"character-style-models\"},{\"depth\":3,\"title\":\"Font style models: a self-supervised approach\",\"slug\":\"font-style-models-a-self-supervised-approach\"},{\"depth\":3,\"title\":\"Font style models: fonts as 26-channel images\",\"slug\":\"font-style-models-fonts-as-26-channel-images\"},{\"depth\":2,\"title\":\"Lessons in MLOps\",\"slug\":\"lessons-in-mlops\"}],\"type\":\"article\",\"html\":\"\"},{\"title\":\"Angular Autoencoders for Dimensionality Reduction\",\"image\":\"/angular-autoencoder/images/angular_autoencoder_gmm.gif\",\"created\":\"2019-02-25T00:00:00.000Z\",\"tags\":[\"dimensionality reduction\",\"auto encoder\"],\"updated\":\"2024-01-21T20:10:06.843Z\",\"images\":[],\"slug\":\"/angular-autoencoder/+page.svelte.md\",\"path\":\"/angular-autoencoder\",\"toc\":[{\"depth\":2,\"title\":\"Motivation\",\"slug\":\"motivation\"},{\"depth\":2,\"title\":\"Formulation\",\"slug\":\"formulation\"},{\"depth\":2,\"title\":\"Architecture\",\"slug\":\"architecture\"},{\"depth\":2,\"title\":\"Implementation details\",\"slug\":\"implementation-details\"},{\"depth\":2,\"title\":\"A toy example\",\"slug\":\"a-toy-example\"},{\"depth\":2,\"title\":\"Reuters data\",\"slug\":\"reuters-data\"},{\"depth\":3,\"title\":\"Reuters data: ordinary autoencoder\",\"slug\":\"reuters-data-ordinary-autoencoder\"},{\"depth\":3,\"title\":\"Reuters data: Angular autoencoder\",\"slug\":\"reuters-data-angular-autoencoder\"},{\"depth\":2,\"title\":\"Legal texts data\",\"slug\":\"legal-texts-data\"},{\"depth\":3,\"title\":\"Legal texts data: ordinary autoencoder\",\"slug\":\"legal-texts-data-ordinary-autoencoder\"},{\"depth\":3,\"title\":\"Legal texts data: angular autoencoder\",\"slug\":\"legal-texts-data-angular-autoencoder\"},{\"depth\":2,\"title\":\"Hand posture data\",\"slug\":\"hand-posture-data\"},{\"depth\":3,\"title\":\"Hand posture data: ordinary autoencoder\",\"slug\":\"hand-posture-data-ordinary-autoencoder\"},{\"depth\":3,\"title\":\"Hand posture data: angular autoencoder\",\"slug\":\"hand-posture-data-angular-autoencoder\"},{\"depth\":2,\"title\":\"Generalization\",\"slug\":\"generalization\"},{\"depth\":2,\"title\":\"Summary\",\"slug\":\"summary\"},{\"depth\":2,\"title\":\"Source code\",\"slug\":\"source-code\"}],\"type\":\"article\",\"html\":\"\"},{\"title\":\"About\",\"created\":\"2019-01-01T00:00:00.000Z\",\"edited\":\"2024-01-20T00:00:00.000Z\",\"updated\":\"2024-01-21T20:10:06.839Z\",\"images\":[],\"tags\":[],\"slug\":\"/about/+page.md\",\"path\":\"/about\",\"toc\":false,\"type\":\"article\",\"html\":\"\"}]"}</script>
			<script>
				{
					__sveltekit_sexkgj = {
						base: new URL("..", location).pathname.slice(0, -1),
						env: {}
					};

					const element = document.currentScript.parentElement;

					const data = [null,null];

					Promise.all([
						import("../_app/immutable/entry/start.18c6e970.js"),
						import("../_app/immutable/entry/app.fc048ece.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 5],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
  </body>
</html>
